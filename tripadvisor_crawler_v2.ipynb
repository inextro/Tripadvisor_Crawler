{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d8b687f-a0ae-4dd8-b11a-430eeb8c8bd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tripadvisor Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff28ddc-9e7f-4178-b835-0e3d8ec4601d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c63d2-8b2c-4e62-b5e6-77f1381d96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad8681-c3ec-4384-9d93-c22e11e0ebb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc7f70-8c6a-479b-a1af-31df0ea533ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_parser(user_id):\n",
    "    reviewer_id, review_id = user_id[4:].split('-')[0], user_id[4:].split('_')[1]\n",
    "    \n",
    "    return reviewer_id, review_id\n",
    "\n",
    "\n",
    "def get_url(hotel_id, review_id):\n",
    "    url = base_url + hotel_id + '-r' + review_id\n",
    "    \n",
    "    return url\n",
    "    \n",
    "    \n",
    "def is_partnership():\n",
    "    user_number = driver.current_url.split('-')[3][1:]\n",
    "    xpath = '//*[@id=\"review_' + str(user_number) + '\"]/div/div[2]/div[6]/div'\n",
    "    \n",
    "    partner_text = driver.find_element_by_xpath(xpath).text\n",
    "    \n",
    "    if 'Review collected in partnership with' in partner_text:\n",
    "        isPartnership = 1\n",
    "    \n",
    "    else:\n",
    "        isPartnership = 0\n",
    "    \n",
    "    return isPartnership"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc3da4-563c-4bdc-8a3c-ba153daa2467",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1458513a-4177-4ebc-95ec-ddb8bf5fe1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hotel data\n",
    "target_hotels = pd.read_csv('data/new_targets.txt', sep='\\n', names=['hotel']) # hotel list\n",
    "hotel_ids = pd.read_excel('data/hotel_id.xlsx', index_col=0) # hotel id\n",
    "\n",
    "# drop Hanbee hotel\n",
    "target_hotels = target_hotels.drop(labels=3, axis=0).reset_index(drop=True)\n",
    "hotel_ids = hotel_ids.dropna(axis=0, how='any', subset=['id']).reset_index(drop=True)\n",
    "\n",
    "# base urls\n",
    "base_url = 'https://www.tripadvisor.com/ShowUserReviews-'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2a6b0-e9f0-44b8-873f-02dce005f393",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588689d-2b6a-4101-91b3-cc8636c56a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# webdriver\n",
    "driver = webdriver.Chrome(executable_path='E:/chromedriver.exe')\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# crawling\n",
    "for i, target_hotel in enumerate(target_hotels['hotel']): # target_hotels['hotel'][:index] -> number of hotels to be crwaled\n",
    "    uid = []\n",
    "    reviewer_id = []\n",
    "    review_id = []\n",
    "    date = []\n",
    "    title = []\n",
    "    review = []\n",
    "    is_partner = []\n",
    "    \n",
    "    user_ids = pd.read_csv('data/target_indivs/' + target_hotel, sep='\\n', names=['user_id'])\n",
    "    hotel_id = hotel_ids.loc[hotel_ids['hotel'] == target_hotel]['id'].values[0]\n",
    "    \n",
    "    print(target_hotel)\n",
    "    print(str(i + 1) + 'th hotel out of ' + str(len(target_hotels['hotel'])) + ' hotels.') # target_hotels['hotel'][:index] -> number of hotels to be crawled\n",
    "    \n",
    "    for j, user_id in enumerate(user_ids['user_id']): # user_ids['user_id'][:index] -> number of users to be crawled\n",
    "        print(str(j + 1) + 'th user out of ' + str(len(user_ids['user_id'])) + ' users.') # user_ids['user_id'][:index] -> number of users to be crawled\n",
    "        \n",
    "        rvwer_id, rvw_id = id_parser(user_id=user_id)\n",
    "        \n",
    "        driver.get(url=get_url(hotel_id=hotel_id, review_id=rvw_id))\n",
    "        time.sleep(2)\n",
    "        \n",
    "        try:\n",
    "            more_button = driver.find_elements_by_css_selector('.ulBlueLinks')[0]\n",
    "            \n",
    "        except IndexError: # no more_button\n",
    "            # append information\n",
    "            uid.append(user_id)\n",
    "            reviewer_id.append(rvwer_id)\n",
    "            review_id.append(rvw_id)\n",
    "            \n",
    "            try:\n",
    "                date.append(driver.find_element_by_class_name('ratingDate').text)\n",
    "                title.append(driver.find_element_by_id('HEADING').text)\n",
    "                review.append(driver.find_element_by_class_name('fullText').text)\n",
    "                \n",
    "                # isPartnership\n",
    "                isPartnership = is_partnership()\n",
    "                is_partner.append(isPartnership)\n",
    "                \n",
    "            except NoSuchElementException:\n",
    "                date.append('The review has been removed')\n",
    "                title.append('The review has been removed')\n",
    "                review.append('The review has been removed')\n",
    "                is_partner.append(0)\n",
    "            \n",
    "        else:\n",
    "            # click more_button\n",
    "            driver.execute_script('arguments[0].click();', more_button)\n",
    "            \n",
    "            # append information\n",
    "            uid.append(user_id)\n",
    "            reviewer_id.append(rvwer_id)\n",
    "            review_id.append(rvw_id)\n",
    "            \n",
    "            try:\n",
    "                date.append(driver.find_element_by_class_name('ratingDate').text)\n",
    "                title.append(driver.find_element_by_id('HEADING').text)\n",
    "                review.append(driver.find_element_by_class_name('fullText').text)\n",
    "            \n",
    "                # isPartnership\n",
    "                isPartnership = is_partnership()\n",
    "                is_partner.append(isPartnership)\n",
    "            \n",
    "            except NoSuchElementException:\n",
    "                date.append('The review has been removed')\n",
    "                title.append('The review has been removed')\n",
    "                review.append('The review has been removed')\n",
    "                is_partner.append(0)\n",
    "            \n",
    "    print('='*150)\n",
    "    \n",
    "    crawled_data = pd.DataFrame(data={'uid': uid, \n",
    "                                     'reviewer_id': reviewer_id, \n",
    "                                     'review_id': review_id, \n",
    "                                     'date': date, \n",
    "                                     'title': title, \n",
    "                                     'review': review, \n",
    "                                     'isPartner': is_partner})\n",
    "    \n",
    "    crawled_data.to_csv('E:/jupyter/project/gtm/crawled_data/' + target_hotel[:-len('_trgt_inds.txt')] + '.csv', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2007dfa3-9375-4c5b-b0cc-4f769eeed80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
